{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-MNIST Classification\n",
    "## Jacob Gomez Rubio and Brandon Ferencik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt   # plot results\n",
    "from sklearn.model_selection import KFold   # CV\n",
    "from sklearn.decomposition import PCA # dimensionality reduction\n",
    "from sklearn.neighbors import KNeighborsClassifier   # kNN Model\n",
    "from sklearn.neural_network import MLPClassifier     # NN Model\n",
    "# import timeit   # time computations\n",
    "from tqdm import tqdm_notebook # loading bar to show progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load images from same directory\n",
    "X_train = np.load(\"fmnist-train-imgs.npz\")['X']\n",
    "X_test = np.load(\"fmnist-test-imgs.npz\")['X']\n",
    "Y_train = np.load(\"fmnist-train-labels.npz\")['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size: (42000, 784)\n",
      "test set size: (28000, 784)\n",
      "label size (should be same as training set size): (42000,)\n"
     ]
    }
   ],
   "source": [
    "print('training set size: {}'.format(X_train.shape))\n",
    "print('test set size: {}'.format(X_test.shape))\n",
    "print('label size (should be same as training set size): {}'.format(Y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getAcc(y_pred,y_test): \n",
    "    return np.mean(y_pred==y_test * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.91 ms\n"
     ]
    }
   ],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=9)\n",
    "x = np.linspace(0.01, 1, 100) # [0.01, 1] closed interval\n",
    "time = np.zeros(len(x))\n",
    "acc_average = np.zeros(len(x)) \n",
    "acc_fold = np.zeros(kfold.n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing results kNN with PCA reduction\n",
    "Since while knn is an accurate way to predict an input, it is more computationally intensive than other model approaches. Thus, we will compromise between accuracy and dimensionality by using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0ecc9b5560ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# across all folds and elapsed time to make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# create test/train copies to test with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX_trainCopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Loop that increases dimension % and makes kNN predictions based \n",
    "    # on dimension size.\n",
    "# Outputs the average accuracy achieved.\n",
    "# across all folds and elapsed time to make predictions\n",
    "\n",
    "for i in tqdm_notebook(range(len(x))): \n",
    "    # create test/train copies to test with\n",
    "    X_trainCopy = X_train\n",
    "    X_testCopy = X_test\n",
    "    pca = PCA(n_components=x[i]) # x is 0.01, 0.02, ... , 1\n",
    "\n",
    "    # train/test copies now have n% dimensionality with PCA\n",
    "    X_trainCopy = pca.fit_transform(X_trainCopy)\n",
    "    X_testCopy = pca.fit_transform(X_testCopy)\n",
    "    \n",
    "    # fit knn model to newly transformed variables (or full dataset if x[i]=1)\n",
    "    kNNmodel.fit(X_trainCopy,Y_train)\n",
    "    # timer for gauging performance time\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    j=0\n",
    "    for train_index, test_index in kfold.split(X_trainCopy):\n",
    "        x_train, x_test = X_trainCopy[train_index], X_trainCopy[test_index]\n",
    "        y_train, y_test = Y_train[train_index], Y_train[test_index]\n",
    "        \n",
    "        y_pred = kNNmodel.predict(x_test) # compute y_pred values\n",
    "        acc_fold[j] = getAcc(y_pred,y_test) # where (y_pred == y_test)\n",
    "        print(\"K-Fold acc (%d%% dimensionality): %.5f\" % (x[i]*100, acc_fold[j]))\n",
    "        j+=1\n",
    "        \n",
    "    acc_average[i] = np.mean(acc_fold)\n",
    "    end = timeit.default_timer()\n",
    "    time[i] = end.real - start.real\n",
    "    \n",
    "    print(\"Avg acc (%d%% dimensionality): %.5f\" %(x[i]*100, acc_average[i]))\n",
    "    print(\"Elapsed Time (%d%% dimensionality): %.3f sec\\n\" %(x[i]*100, time[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 258 ms\n"
     ]
    }
   ],
   "source": [
    "plt.plot(x[:-1], acc_average[:-1], 'r-', alpha=0.7)\n",
    "plt.title(\"Dimension vs Accuracy\")\n",
    "plt.xlabel(\"Dimension (%)\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest accuracy (0.886) at index 92\n"
     ]
    }
   ],
   "source": [
    "# improvements in output accuracy from difference in dimensionality\n",
    "print(\"highest accuracy (%.3f) at index\" % \\\n",
    "      acc_average.max(), acc_average.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "After testing different amounts of the `n_components` parameter with the kNN algorithm, we are able to get, at best, **89% accuracy with 92% of our dataset using PCA.**\n",
    "\n",
    "We can go further, though. kNN accuracy only differs by ~3-5% when reducing dimensionality from 92% to 70%. Thus, we can still achieve **accuracy of 85% with only 70% of the dataset** using Principal Component Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, time, 'bo', alpha=0.4)\n",
    "plt.title(\"Dimension vs Time\")\n",
    "plt.xlabel(\"Dimension (%)\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.25 ms\n"
     ]
    }
   ],
   "source": [
    "time[92], time[70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN model, learning_rate set to adaptive in order to adjust eta in the gradient descent process\n",
    "X_trainCopy = X_train\n",
    "X_testCopy = X_test\n",
    "# default hidden_layers = (100,)\n",
    "model = MLPClassifier(random_state=1,verbose=True,\\\n",
    "                      solver='adam',learning_rate='adaptive',\\\n",
    "                      learning_rate_init=1e-3)\n",
    "acc_fold = np.zeros(kfold.n_splits) # using 4 splits as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions to be submitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.34788806\n",
      "Iteration 2, loss = 1.37718184\n",
      "Iteration 3, loss = 0.94525043\n",
      "Iteration 4, loss = 0.74090575\n",
      "Iteration 5, loss = 0.65289377\n",
      "Iteration 6, loss = 0.59467840\n",
      "Iteration 7, loss = 0.54424723\n",
      "Iteration 8, loss = 0.50845205\n",
      "Iteration 9, loss = 0.48603448\n",
      "Iteration 10, loss = 0.47131538\n",
      "Iteration 11, loss = 0.44876464\n",
      "Iteration 12, loss = 0.43568092\n",
      "Iteration 13, loss = 0.43445002\n",
      "Iteration 14, loss = 0.42007562\n",
      "Iteration 15, loss = 0.41420379\n",
      "Iteration 16, loss = 0.40771751\n",
      "Iteration 17, loss = 0.40536404\n",
      "Iteration 18, loss = 0.39334342\n",
      "Iteration 19, loss = 0.40861090\n",
      "Iteration 20, loss = 0.40736722\n",
      "Iteration 21, loss = 0.39561334\n",
      "Iteration 22, loss = 0.39668018\n",
      "Iteration 23, loss = 0.39123701\n",
      "Iteration 24, loss = 0.38738328\n",
      "Iteration 25, loss = 0.38636492\n",
      "Iteration 26, loss = 0.38107564\n",
      "Iteration 27, loss = 0.38344481\n",
      "Iteration 28, loss = 0.37148474\n",
      "Iteration 29, loss = 0.36804784\n",
      "Iteration 30, loss = 0.37646687\n",
      "Iteration 31, loss = 0.36511973\n",
      "Iteration 32, loss = 0.35767727\n",
      "Iteration 33, loss = 0.35381569\n",
      "Iteration 34, loss = 0.35998092\n",
      "Iteration 35, loss = 0.35946931\n",
      "Iteration 36, loss = 0.35059728\n",
      "Iteration 37, loss = 0.34552608\n",
      "Iteration 38, loss = 0.34805729\n",
      "Iteration 39, loss = 0.34092192\n",
      "Iteration 40, loss = 0.34698126\n",
      "Iteration 41, loss = 0.34082767\n",
      "Iteration 42, loss = 0.33523194\n",
      "Iteration 43, loss = 0.33857946\n",
      "Iteration 44, loss = 0.33028980\n",
      "Iteration 45, loss = 0.33180448\n",
      "Iteration 46, loss = 0.33408129\n",
      "Iteration 47, loss = 0.33401366\n",
      "Iteration 48, loss = 0.32933056\n",
      "Iteration 49, loss = 0.32477429\n",
      "Iteration 50, loss = 0.32702014\n",
      "Iteration 51, loss = 0.32135353\n",
      "Iteration 52, loss = 0.31861797\n",
      "Iteration 53, loss = 0.31636646\n",
      "Iteration 54, loss = 0.31823184\n",
      "Iteration 55, loss = 0.31703978\n",
      "Iteration 56, loss = 0.31458424\n",
      "Iteration 57, loss = 0.30277925\n",
      "Iteration 58, loss = 0.30268970\n",
      "Iteration 59, loss = 0.31443040\n",
      "Iteration 60, loss = 0.30545932\n",
      "Iteration 61, loss = 0.30725288\n",
      "Iteration 62, loss = 0.30147615\n",
      "Iteration 63, loss = 0.30518684\n",
      "Iteration 64, loss = 0.29803408\n",
      "Iteration 65, loss = 0.30056654\n",
      "Iteration 66, loss = 0.31258686\n",
      "Iteration 67, loss = 0.29548985\n",
      "Iteration 68, loss = 0.31185377\n",
      "Iteration 69, loss = 0.29868180\n",
      "Iteration 70, loss = 0.29530301\n",
      "Iteration 71, loss = 0.29056484\n",
      "Iteration 72, loss = 0.29310114\n",
      "Iteration 73, loss = 0.28820985\n",
      "Iteration 74, loss = 0.28731322\n",
      "Iteration 75, loss = 0.29174179\n",
      "Iteration 76, loss = 0.28900199\n",
      "Iteration 77, loss = 0.29316915\n",
      "Iteration 78, loss = 0.29252271\n",
      "Iteration 79, loss = 0.28126788\n",
      "Iteration 80, loss = 0.29002498\n",
      "Iteration 81, loss = 0.28738610\n",
      "Iteration 82, loss = 0.28454986\n",
      "Iteration 83, loss = 0.28725858\n",
      "Iteration 84, loss = 0.28195491\n",
      "Iteration 85, loss = 0.29249413\n",
      "Iteration 86, loss = 0.28522439\n",
      "Iteration 87, loss = 0.27018332\n",
      "Iteration 88, loss = 0.28931381\n",
      "Iteration 89, loss = 0.28890522\n",
      "Iteration 90, loss = 0.27572525\n",
      "Iteration 91, loss = 0.27481951\n",
      "Iteration 92, loss = 0.27455164\n",
      "Iteration 93, loss = 0.27608648\n",
      "Iteration 94, loss = 0.27371778\n",
      "Iteration 95, loss = 0.27535698\n",
      "Iteration 96, loss = 0.28214100\n",
      "Iteration 97, loss = 0.27321837\n",
      "Iteration 98, loss = 0.27631447\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation using k = 4 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10500 10501 10502 ... 41997 41998 41999]\n",
      "Iteration 1, loss = 5.16662332\n",
      "Iteration 2, loss = 2.46236417\n",
      "Iteration 3, loss = 1.18672562\n",
      "Iteration 4, loss = 0.84778341\n",
      "Iteration 5, loss = 0.72700102\n",
      "Iteration 6, loss = 0.65465053\n",
      "Iteration 7, loss = 0.60830419\n",
      "Iteration 8, loss = 0.57413584\n",
      "Iteration 9, loss = 0.54226855\n",
      "Iteration 10, loss = 0.52221683\n",
      "Iteration 11, loss = 0.49532480\n",
      "Iteration 12, loss = 0.48578054\n",
      "Iteration 13, loss = 0.46446356\n",
      "Iteration 14, loss = 0.44257714\n",
      "Iteration 15, loss = 0.43125571\n",
      "Iteration 16, loss = 0.42217206\n",
      "Iteration 17, loss = 0.42489891\n",
      "Iteration 18, loss = 0.40358758\n",
      "Iteration 19, loss = 0.39255587\n",
      "Iteration 20, loss = 0.39202323\n",
      "Iteration 21, loss = 0.38369078\n",
      "Iteration 22, loss = 0.38393426\n",
      "Iteration 23, loss = 0.38158798\n",
      "Iteration 24, loss = 0.38265073\n",
      "Iteration 25, loss = 0.36483993\n",
      "Iteration 26, loss = 0.35943331\n",
      "Iteration 27, loss = 0.35913712\n",
      "Iteration 28, loss = 0.36545533\n",
      "Iteration 29, loss = 0.36090405\n",
      "Iteration 30, loss = 0.36989724\n",
      "Iteration 31, loss = 0.35865798\n",
      "Iteration 32, loss = 0.35479417\n",
      "Iteration 33, loss = 0.34839881\n",
      "Iteration 34, loss = 0.33520151\n",
      "Iteration 35, loss = 0.33475419\n",
      "Iteration 36, loss = 0.33613939\n",
      "Iteration 37, loss = 0.35110245\n",
      "Iteration 38, loss = 0.34617320\n",
      "Iteration 39, loss = 0.32504858\n",
      "Iteration 40, loss = 0.33469795\n",
      "Iteration 41, loss = 0.33211940\n",
      "Iteration 42, loss = 0.32250065\n",
      "Iteration 43, loss = 0.32071939\n",
      "Iteration 44, loss = 0.32855543\n",
      "Iteration 45, loss = 0.31926584\n",
      "Iteration 46, loss = 0.31610176\n",
      "Iteration 47, loss = 0.31883805\n",
      "Iteration 48, loss = 0.31848986\n",
      "Iteration 49, loss = 0.31780542\n",
      "Iteration 50, loss = 0.30786739\n",
      "Iteration 51, loss = 0.31982942\n",
      "Iteration 52, loss = 0.29978579\n",
      "Iteration 53, loss = 0.30024326\n",
      "Iteration 54, loss = 0.31081296\n",
      "Iteration 55, loss = 0.30638402\n",
      "Iteration 56, loss = 0.30113565\n",
      "Iteration 57, loss = 0.29238675\n",
      "Iteration 58, loss = 0.30549471\n",
      "Iteration 59, loss = 0.29739992\n",
      "Iteration 60, loss = 0.29521939\n",
      "Iteration 61, loss = 0.29530192\n",
      "Iteration 62, loss = 0.29297733\n",
      "Iteration 63, loss = 0.28294665\n",
      "Iteration 64, loss = 0.29374374\n",
      "Iteration 65, loss = 0.29642045\n",
      "Iteration 66, loss = 0.28008361\n",
      "Iteration 67, loss = 0.28354050\n",
      "Iteration 68, loss = 0.28653119\n",
      "Iteration 69, loss = 0.29044512\n",
      "Iteration 70, loss = 0.27245492\n",
      "Iteration 71, loss = 0.28392725\n",
      "Iteration 72, loss = 0.27840465\n",
      "Iteration 73, loss = 0.27548130\n",
      "Iteration 74, loss = 0.27997232\n",
      "Iteration 75, loss = 0.28146479\n",
      "Iteration 76, loss = 0.27790829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacob/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on fold 1: 0.85610 \n",
      "\n",
      "[    0     1     2 ... 41997 41998 41999]\n",
      "Iteration 1, loss = 5.20301117\n",
      "Iteration 2, loss = 2.25205316\n",
      "Iteration 3, loss = 1.09968552\n",
      "Iteration 4, loss = 0.84971929\n",
      "Iteration 5, loss = 0.72589082\n",
      "Iteration 6, loss = 0.65192348\n",
      "Iteration 7, loss = 0.60956955\n",
      "Iteration 8, loss = 0.56954028\n",
      "Iteration 9, loss = 0.53653514\n",
      "Iteration 10, loss = 0.50889464\n",
      "Iteration 11, loss = 0.49339429\n",
      "Iteration 12, loss = 0.47005188\n",
      "Iteration 13, loss = 0.45524062\n",
      "Iteration 14, loss = 0.43738171\n",
      "Iteration 15, loss = 0.43071600\n",
      "Iteration 16, loss = 0.41536261\n",
      "Iteration 17, loss = 0.42410570\n",
      "Iteration 18, loss = 0.39296365\n",
      "Iteration 19, loss = 0.38576063\n",
      "Iteration 20, loss = 0.38509394\n",
      "Iteration 21, loss = 0.38736720\n",
      "Iteration 22, loss = 0.38793805\n",
      "Iteration 23, loss = 0.38184639\n",
      "Iteration 24, loss = 0.38232236\n",
      "Iteration 25, loss = 0.36977717\n",
      "Iteration 26, loss = 0.36344558\n",
      "Iteration 27, loss = 0.37379463\n",
      "Iteration 28, loss = 0.35751448\n",
      "Iteration 29, loss = 0.34689101\n",
      "Iteration 30, loss = 0.34981910\n",
      "Iteration 31, loss = 0.34670674\n",
      "Iteration 32, loss = 0.34317846\n",
      "Iteration 33, loss = 0.35079855\n",
      "Iteration 34, loss = 0.33519546\n",
      "Iteration 35, loss = 0.34792601\n",
      "Iteration 36, loss = 0.33800250\n",
      "Iteration 37, loss = 0.33517721\n",
      "Iteration 38, loss = 0.33411001\n",
      "Iteration 39, loss = 0.33489945\n",
      "Iteration 40, loss = 0.33109765\n",
      "Iteration 41, loss = 0.32250972\n",
      "Iteration 42, loss = 0.33048025\n",
      "Iteration 43, loss = 0.33213629\n",
      "Iteration 44, loss = 0.32370085\n",
      "Iteration 45, loss = 0.31480962\n",
      "Iteration 46, loss = 0.32412528\n",
      "Iteration 47, loss = 0.31947316\n",
      "Iteration 48, loss = 0.31854192\n",
      "Iteration 49, loss = 0.31218247\n",
      "Iteration 50, loss = 0.31998851\n",
      "Iteration 51, loss = 0.31380240\n",
      "Iteration 52, loss = 0.30875300\n",
      "Iteration 53, loss = 0.29924909\n",
      "Iteration 54, loss = 0.30377455\n",
      "Iteration 55, loss = 0.30531111\n",
      "Iteration 56, loss = 0.31183135\n",
      "Iteration 57, loss = 0.29713589\n",
      "Iteration 58, loss = 0.30495499\n",
      "Iteration 59, loss = 0.29985279\n",
      "Iteration 60, loss = 0.30340370\n",
      "Iteration 61, loss = 0.29559052\n",
      "Iteration 62, loss = 0.30646206\n",
      "Iteration 63, loss = 0.28797865\n",
      "Iteration 64, loss = 0.28651429\n",
      "Iteration 65, loss = 0.29630043\n",
      "Iteration 66, loss = 0.28369087\n",
      "Iteration 67, loss = 0.28866961\n",
      "Iteration 68, loss = 0.29622675\n",
      "Iteration 69, loss = 0.29393565\n",
      "Iteration 70, loss = 0.27977710\n",
      "Iteration 71, loss = 0.27526110\n",
      "Iteration 72, loss = 0.28609348\n",
      "Iteration 73, loss = 0.28994276\n",
      "Iteration 74, loss = 0.28964200\n",
      "Iteration 75, loss = 0.28637099\n",
      "Iteration 76, loss = 0.29146683\n",
      "Iteration 77, loss = 0.27914870\n",
      "Iteration 78, loss = 0.27504108\n",
      "Iteration 79, loss = 0.26892784\n",
      "Iteration 80, loss = 0.29513486\n",
      "Iteration 81, loss = 0.28968417\n",
      "Iteration 82, loss = 0.27337054\n",
      "Iteration 83, loss = 0.27263260\n",
      "Iteration 84, loss = 0.27930294\n",
      "Iteration 85, loss = 0.27798610\n"
     ]
    }
   ],
   "source": [
    "#Trains NN model across all folds and asseses acccuracy of the predictions\n",
    "#Outputs the average accuracy achieved\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train):\n",
    "    print(train_index)\n",
    "    x_train, x_test = X_train[train_index], X_train[test_index]\n",
    "    y_train, y_test = Y_train[train_index], Y_train[test_index]\n",
    "    \n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    acc_fold[i] = getAcc(y_pred, y_test)\n",
    "    print(\"Accuracy on fold %d: %.5f \\n\" % (i+1, acc_fold[i]))\n",
    "    i= i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with a Neural Network is much faster.\n",
    "The above neural network is able to classify with 85% accuracy using full dimensionality of the dataset. Computation time averages 6-7 minutes whereas kNN took an average of 60 minutes.\n",
    "\n",
    "We can safely conclude that the model is trained ~10x faster by means of a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8509047619047619\n",
      "time: 978 µs\n"
     ]
    }
   ],
   "source": [
    "acc_average = np.mean(acc_fold)\n",
    "print(acc_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 152 ms\n"
     ]
    }
   ],
   "source": [
    "solutions = np.zeros((28000, 2))\n",
    "solutions[:,0] = np.arange(1,28001)\n",
    "solutions[:,1] = y_pred\n",
    "solutions = solutions.astype(int)\n",
    "np.savetxt(\"solutions-jacobgomez-brandonferencik.csv\", solutions, \n",
    "           fmt='%s', header = 'Id,Category', delimiter = ',', comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Outline",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
